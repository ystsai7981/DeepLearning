{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b15264fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load sample.py\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "from os import system\n",
    "from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23740da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"========================================================================================\n",
    "The sample.py includes the following template functions:\n",
    "\n",
    "1. Encoder, decoder\n",
    "2. Training function\n",
    "3. BLEU-4 score function\n",
    "\n",
    "You have to modify them to complete the lab.\n",
    "In addition, there are still other functions that you have to \n",
    "implement by yourself.\n",
    "\n",
    "1. Your own dataloader (design in your own way, not necessary Pytorch Dataloader)\n",
    "2. Output your results (BLEU-4 score, correction words)\n",
    "3. Plot loss/score\n",
    "4. Load/save weights\n",
    "========================================================================================\"\"\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#----------Hyper Parameters----------#\n",
    "embedding_size = 32\n",
    "hidden_size = 512\n",
    "#The number of vocabulary\n",
    "vocab_size = 28\n",
    "teacher_forcing_ratio = 0.5\n",
    "LR = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f00905e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5154486831107657\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "#Example inputs of compute_bleu\n",
    "################################\n",
    "#The target word\n",
    "reference = 'variable'\n",
    "#The word generated by your model\n",
    "output = 'varable'\n",
    "\n",
    "#compute BLEU-4 score\n",
    "def compute_bleu(output, reference):\n",
    "    cc = SmoothingFunction()\n",
    "    if len(reference) == 3:\n",
    "        weights = (0.33,0.33,0.33)\n",
    "    else:\n",
    "        weights = (0.25,0.25,0.25,0.25)\n",
    "    return sentence_bleu([reference], output,weights=weights,smoothing_function=cc.method1)\n",
    "\n",
    "print(compute_bleu(output, reference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc7d41e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "char2index = {\"SOS\": 0, \"EOS\": 1}\n",
    "index2char = {0: \"SOS\", 1: \"EOS\"}\n",
    "a2z = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "for index, char in enumerate(a2z, 2):\n",
    "    char2index[char] = index\n",
    "    index2char[index] = char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "837514fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"train.json\") as f:\n",
    "    line = json.load(f)\n",
    "\n",
    "data_list = []\n",
    "label_list = []\n",
    "for pair in line:\n",
    "    label_idx = []\n",
    "    for character in pair[\"target\"]:\n",
    "        label_idx.append(char2index[character])\n",
    "    label_idx = torch.tensor(label_idx)\n",
    "    for word in pair[\"input\"]:\n",
    "        word_idx = []\n",
    "        for character in word:\n",
    "            word_idx.append(char2index[character])\n",
    "        word_idx.append(char2index[\"EOS\"])\n",
    "        word_idx = torch.tensor(word_idx)\n",
    "        data_list.append(word_idx)\n",
    "        label_list.append(label_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9b03cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ToOneHot(input_tensor):\n",
    "    output_tensor = torch.zeros(input_tensor.shape[0], 1, 28)\n",
    "    for i in range(input_tensor.shape[0]):\n",
    "        output_tensor[i][0][input_tensor[i]] = 1\n",
    "    return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56ab7e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.gru = nn.GRU(embedding_size, hidden_size)\n",
    "        self.rnn = nn.RNN(embedding_size, hidden_size)\n",
    "#         self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(-1, 1, self.embedding_size)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5440ec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoder\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.teacher_forcing_ratio = 0.5\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
    "        self.gru = nn.GRU(embedding_size, hidden_size)\n",
    "        self.rnn = nn.RNN(embedding_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(-1, 1, self.embedding_size)\n",
    "#         output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.log_softmax(self.out(output))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcd31e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_fn):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    target_tensor = target_tensor.to(device)\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = len(target_tensor)\n",
    "    \n",
    "    target_1hot = ToOneHot(target_tensor).to(device)\n",
    "#     encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "    loss = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    #----------sequence to sequence part for encoder----------#\n",
    "    encoder_output, encoder_hidden = encoder(input_tensor.to(device), encoder_hidden)\n",
    "    decoder_input = torch.tensor([SOS_token], device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "    decoder_outputs = torch.zeros(target_length, 1, 28).to(device)\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\t\n",
    "\n",
    "    #----------sequence to sequence part for decoder----------#\n",
    "    \n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        decoder_outputs[di][0] = decoder_output\n",
    "        loss += loss_fn(decoder_output.view(1, -1), target_1hot[di])\n",
    "        \n",
    "        if use_teacher_forcing:\n",
    "            decoder_input = target_tensor[di].view(1,).to(device)  # Teacher forcing\n",
    "        else:\n",
    "            decoder_input = decoder_output.argmax()\n",
    "\n",
    "#     decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "#     loss = loss_fn(decoder_output.view(1, -1), ToOneHot(torch.tensor([EOS_token]))[0].view(1, -1).to(device))\n",
    "#     total_loss += loss.item()\n",
    "\n",
    "#     else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "#         for di in range(target_length):\n",
    "#             decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "#                 decoder_input, decoder_hidden, encoder_outputs)\n",
    "#             topv, topi = decoder_output.topk(1)\n",
    "#             decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "#             loss += criterion(decoder_output, target_tensor[di])\n",
    "#             if decoder_input.item() == EOS_token:\n",
    "#                 break\n",
    "\n",
    "\n",
    "#     print(f\"Loss: {total_loss / target_length}\")\n",
    "#     loss = loss_fn(decoder_outputs.squeeze(1), target_1hot.squeeze(1))\n",
    "#     total_loss += loss.item()\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "#     return total_loss\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb5b91f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d19116a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(data_list, label_list, encoder, decoder, n_iters,\n",
    "               print_every=1000, plot_every=100, learning_rate=0.0001, plot_history=[]):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    # your own dataloader\n",
    "#     training_pairs = ...\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    for i in range(n_iters):\n",
    "#         training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = data_list[i]\n",
    "        target_tensor = label_list[i]\n",
    "#         print(target_tensor)\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, loss_fn)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if (i+1) % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "#             print(print_loss_avg)\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, i / (n_iters+1)),\n",
    "                                         i, i / (n_iters+1) * 100, print_loss_avg), end=\"\\r\")\n",
    "    plot_history.append(plot_loss_total / len(data_list))\n",
    "    print(\"\\n\", plot_loss_total / len(data_list))\n",
    "            \n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b3cdca07",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder1 = EncoderRNN(vocab_size, embedding_size, hidden_size).to(device)\n",
    "decoder1 = DecoderRNN(embedding_size, hidden_size, vocab_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9e26b4da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "006f258e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 0\n",
      "1m 13s (- 0m 5s) (11999 92%) 0.2165\n",
      " 0.1532583442666561\n",
      "Epochs: 1\n",
      "1m 13s (- 0m 5s) (11999 92%) 0.1980\n",
      " 0.14539076105374626\n",
      "Epochs: 2\n",
      "1m 14s (- 0m 5s) (11999 92%) 0.2013\n",
      " 0.1478482631383232\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(f\"Epochs: {i}\")\n",
    "    trainIters(data_list, label_list, encoder1, decoder1, len(data_list), plot_history=plot_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f0ac39f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['u', 'n', 'f', 'a', 'r', 'g', 'e', 't', 'a', 'b', 'l', 'e', 'd']\n"
     ]
    }
   ],
   "source": [
    "word_idx = 47\n",
    "using_data = new_test_data_list\n",
    "using_label = new_test_label_list\n",
    "with torch.no_grad():\n",
    "    init_hid = encoder1.initHidden()\n",
    "    out, hid = encoder1(using_data[word_idx].to(device), init_hid)\n",
    "    dec_hid = hid\n",
    "    dec_in = torch.tensor([SOS_token], device=device)\n",
    "    generated_word = []\n",
    "    for i in range(len(using_label[word_idx])):\n",
    "        dec_out, dec_hid = decoder1(dec_in, dec_hid)\n",
    "        generated_word.append(index2char[dec_out.argmax(dim=2).item()])\n",
    "        dec_in = dec_out.argmax(dim=2).view(1,)\n",
    "        if dec_in.item() == 1:\n",
    "            break\n",
    "    print(generated_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8c9fbfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['u', 'n', 'f', 'o', 'r', 'g', 'e', 't', 't', 'a', 'b', 'l', 'e']\n"
     ]
    }
   ],
   "source": [
    "target_word = []\n",
    "for i in range(len(using_label[word_idx])):\n",
    "    target_word.append(index2char[using_label[word_idx][i].item()])\n",
    "print(target_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "973ca2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5676721706387805"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_bleu(generated_word, target_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1e35594b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.079794388889493, 1.5956861144541354, 1.3052637725144365, 1.136644511603837, 1.0034871931159142, 0.8884981466559769, 0.7831374901858769, 0.6832117146480324, 0.5869414266801734, 0.49503128421234854, 0.41448177575661604, 0.3433761452130524, 0.28486161763931633, 0.23839412807233035, 0.21073689179422125, 0.18983890777578458, 0.17598979590235814, 0.1588104728246828, 0.1532583442666561, 0.14539076105374626, 0.1478482631383232]\n"
     ]
    }
   ],
   "source": [
    "print(plot_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ba8a1379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"test.json\") as f:\n",
    "    line = json.load(f)\n",
    "\n",
    "test_data_list = []\n",
    "test_label_list = []\n",
    "for pair in line:\n",
    "    label_idx = []\n",
    "    for character in pair[\"target\"]:\n",
    "        label_idx.append(char2index[character])\n",
    "    label_idx = torch.tensor(label_idx)\n",
    "    for word in pair[\"input\"]:\n",
    "        word_idx = []\n",
    "        for character in word:\n",
    "            word_idx.append(char2index[character])\n",
    "        word_idx.append(char2index[\"EOS\"])\n",
    "        word_idx = torch.tensor(word_idx)\n",
    "        test_data_list.append(word_idx)\n",
    "        test_label_list.append(label_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9ab9630c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"new_test.json\") as f:\n",
    "    line = json.load(f)\n",
    "\n",
    "new_test_data_list = []\n",
    "new_test_label_list = []\n",
    "for pair in line:\n",
    "    label_idx = []\n",
    "    for character in pair[\"target\"]:\n",
    "        label_idx.append(char2index[character])\n",
    "    label_idx = torch.tensor(label_idx)\n",
    "    for word in pair[\"input\"]:\n",
    "        word_idx = []\n",
    "        for character in word:\n",
    "            word_idx.append(char2index[character])\n",
    "        word_idx.append(char2index[\"EOS\"])\n",
    "        word_idx = torch.tensor(word_idx)\n",
    "        new_test_data_list.append(word_idx)\n",
    "        new_test_label_list.append(label_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297592c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
