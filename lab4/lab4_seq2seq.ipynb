{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19c634c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load sample.py\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.switch_backend('module://matplotlib_inline.backend_inline')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "from os import system\n",
    "from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e36fc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 198964\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c27d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"========================================================================================\n",
    "The sample.py includes the following template functions:\n",
    "\n",
    "1. Encoder, decoder\n",
    "2. Training function\n",
    "3. BLEU-4 score function\n",
    "\n",
    "You have to modify them to complete the lab.\n",
    "In addition, there are still other functions that you have to \n",
    "implement by yourself.\n",
    "\n",
    "1. Your own dataloader (design in your own way, not necessary Pytorch Dataloader)\n",
    "2. Output your results (BLEU-4 score, correction words)\n",
    "3. Plot loss/score\n",
    "4. Load/save weights\n",
    "========================================================================================\"\"\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#----------Hyper Parameters----------#\n",
    "embedding_size = 32\n",
    "hidden_size = 512\n",
    "#The number of vocabulary\n",
    "vocab_size = 28\n",
    "teacher_forcing_ratio = 0.5\n",
    "LR = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4ca9711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5154486831107657\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "#Example inputs of compute_bleu\n",
    "################################\n",
    "#The target word\n",
    "reference = 'variable'\n",
    "#The word generated by your model\n",
    "output = 'varable'\n",
    "\n",
    "#compute BLEU-4 score\n",
    "def compute_bleu(output, reference):\n",
    "    cc = SmoothingFunction()\n",
    "    if len(reference) == 3:\n",
    "        weights = (0.33,0.33,0.33)\n",
    "    else:\n",
    "        weights = (0.25,0.25,0.25,0.25)\n",
    "    return sentence_bleu([reference], output,weights=weights,smoothing_function=cc.method1)\n",
    "\n",
    "print(compute_bleu(output, reference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4b02565",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "char2index = {\"SOS\": 0, \"EOS\": 1}\n",
    "index2char = {0: \"SOS\", 1: \"EOS\"}\n",
    "a2z = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "for index, char in enumerate(a2z, 2):\n",
    "    char2index[char] = index\n",
    "    index2char[index] = char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c77dfe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"train.json\") as f:\n",
    "    line = json.load(f)\n",
    "\n",
    "data_list = []\n",
    "label_list = []\n",
    "for pair in line:\n",
    "    label_idx = []\n",
    "    for character in pair[\"target\"]:\n",
    "        label_idx.append(char2index[character])\n",
    "    label_idx.append(char2index[\"EOS\"])\n",
    "    label_idx = torch.tensor(label_idx)\n",
    "    for word in pair[\"input\"]:\n",
    "        word_idx = []\n",
    "        for character in word:\n",
    "            word_idx.append(char2index[character])\n",
    "        word_idx.append(char2index[\"EOS\"])\n",
    "        word_idx = torch.tensor(word_idx)\n",
    "        data_list.append(word_idx)\n",
    "        label_list.append(label_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4c118e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"test.json\") as f:\n",
    "    line = json.load(f)\n",
    "\n",
    "test_data_list = []\n",
    "test_label_list = []\n",
    "for pair in line:\n",
    "    label_idx = []\n",
    "    for character in pair[\"target\"]:\n",
    "        label_idx.append(char2index[character])\n",
    "    label_idx.append(char2index[\"EOS\"])\n",
    "    label_idx = torch.tensor(label_idx)\n",
    "    for word in pair[\"input\"]:\n",
    "        word_idx = []\n",
    "        for character in word:\n",
    "            word_idx.append(char2index[character])\n",
    "        word_idx.append(char2index[\"EOS\"])\n",
    "        word_idx = torch.tensor(word_idx)\n",
    "        test_data_list.append(word_idx)\n",
    "        test_label_list.append(label_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fde0550e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"new_test.json\") as f:\n",
    "    line = json.load(f)\n",
    "\n",
    "new_test_data_list = []\n",
    "new_test_label_list = []\n",
    "for pair in line:\n",
    "    label_idx = []\n",
    "    for character in pair[\"target\"]:\n",
    "        label_idx.append(char2index[character])\n",
    "    label_idx.append(char2index[\"EOS\"])\n",
    "    label_idx = torch.tensor(label_idx)\n",
    "    for word in pair[\"input\"]:\n",
    "        word_idx = []\n",
    "        for character in word:\n",
    "            word_idx.append(char2index[character])\n",
    "        word_idx.append(char2index[\"EOS\"])\n",
    "        word_idx = torch.tensor(word_idx)\n",
    "        new_test_data_list.append(word_idx)\n",
    "        new_test_label_list.append(label_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f90ecf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ToOneHot(input_tensor):\n",
    "    output_tensor = torch.zeros(input_tensor.shape[0], 1, 28)\n",
    "    for i in range(input_tensor.shape[0]):\n",
    "        output_tensor[i][0][input_tensor[i]] = 1\n",
    "    return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a52e812",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.gru = nn.GRU(embedding_size, hidden_size)\n",
    "        self.rnn = nn.RNN(embedding_size, hidden_size)\n",
    "#         self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(-1, 1, self.embedding_size)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1aa4a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoder\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.teacher_forcing_ratio = 0.5\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
    "        self.gru = nn.GRU(embedding_size, hidden_size)\n",
    "        self.rnn = nn.RNN(embedding_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(-1, 1, self.embedding_size)\n",
    "#         output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.log_softmax(self.out(output))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76c38240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_fn):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    target_tensor = target_tensor.to(device)\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = len(target_tensor)\n",
    "    \n",
    "    target_1hot = ToOneHot(target_tensor).to(device)\n",
    "    loss = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    #----------sequence to sequence part for encoder----------#\n",
    "    encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "    decoder_input = torch.tensor([SOS_token], device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "    decoder_outputs = torch.zeros(target_length, 1, 28).to(device)\n",
    "    EOS = torch.tensor([EOS_token], device=device)\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\t\n",
    "\n",
    "    #----------sequence to sequence part for decoder----------#\n",
    "    \n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "    for di in range(target_length):\n",
    "        if decoder_input == EOS:\n",
    "            break\n",
    "        else:\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            decoder_outputs[di][0] = decoder_output\n",
    "            loss += loss_fn(decoder_output.view(1, -1), target_1hot[di])\n",
    "\n",
    "            if use_teacher_forcing:\n",
    "                decoder_input = target_tensor[di].view(1,).to(device)  # Teacher forcing\n",
    "            else:\n",
    "                decoder_input = decoder_output.argmax()\n",
    "\n",
    "#     loss = loss_fn(decoder_outputs.squeeze(1), target_1hot.squeeze(1))\n",
    "#     total_loss += loss.item()\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "#     return total_loss\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36e99b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79b14d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(data_list, label_list, encoder, decoder, n_iters,\n",
    "               print_every=1000, plot_every=100, learning_rate=0.0001, plot_history=[]):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    # your own dataloader\n",
    "#     training_pairs = ...\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    for i in range(n_iters):\n",
    "#         training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = data_list[i]\n",
    "        target_tensor = label_list[i]\n",
    "#         print(target_tensor)\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, loss_fn)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if (i+1) % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "#             print(print_loss_avg)\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, i / (n_iters+1)),\n",
    "                                         i, i / (n_iters+1) * 100, print_loss_avg), end=\"\\r\")\n",
    "    plot_history.append(plot_loss_total / len(data_list))\n",
    "    print(\"\\nLoss:\", plot_loss_total / len(data_list))\n",
    "            \n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f131256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluate_bleu(test_data, test_label, encoder, decoder):\n",
    "    with torch.no_grad():\n",
    "        total_bleu = 0.\n",
    "        for i in range(len(test_data)):\n",
    "            init_hid = encoder.initHidden()\n",
    "            out, hid = encoder(test_data[i].to(device), init_hid)\n",
    "            dec_hid = hid\n",
    "            dec_in = torch.tensor([SOS_token], device=device)\n",
    "            generated_word = []\n",
    "            while True:\n",
    "                dec_out, dec_hid = decoder(dec_in, dec_hid)\n",
    "                generated_word.append(index2char[dec_out.argmax(dim=2).item()])\n",
    "                dec_in = dec_out.argmax(dim=2).view(1,)\n",
    "                if dec_in.item() == EOS_token:\n",
    "                    break\n",
    "\n",
    "            target_word = []\n",
    "            for j in range(len(test_label[i])):\n",
    "                target_word.append(index2char[test_label[i][j].item()])\n",
    "                \n",
    "            total_bleu += compute_bleu(generated_word, target_word)\n",
    "        return total_bleu / len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48c3bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder1 = EncoderRNN(vocab_size, embedding_size, hidden_size).to(device)\n",
    "decoder1 = DecoderRNN(embedding_size, hidden_size, vocab_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a4176e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_history = []\n",
    "bleu_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddffba3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 0\n",
      "1m 17s (- 0m 6s) (11999 92%) 1.93490\n",
      "Loss: 1.8997480002440437\n",
      "Bleu score: 0.11793764342129111\n",
      "Epochs: 1\n",
      "1m 19s (- 0m 6s) (11999 92%) 1.40448\n",
      "Loss: 1.4808628321279897\n",
      "Bleu score: 0.2172421899996778\n",
      "Epochs: 2\n",
      "1m 20s (- 0m 6s) (11999 92%) 1.09415\n",
      "Loss: 1.2197327714804789\n",
      "Bleu score: 0.2952050876902603\n",
      "Epochs: 3\n",
      "1m 20s (- 0m 6s) (11999 92%) 0.91235\n",
      "Loss: 1.0731065150832484\n",
      "Bleu score: 0.41156354571503223\n",
      "Epochs: 4\n",
      "1m 20s (- 0m 6s) (11999 92%) 0.75704\n",
      "Loss: 0.9605037884187603\n",
      "Bleu score: 0.4706009144508546\n",
      "Epochs: 5\n",
      "1m 20s (- 0m 6s) (11999 92%) 0.65793\n",
      "Loss: 0.8612166672532952\n",
      "Bleu score: 0.49993660401800905\n",
      "Epochs: 6\n",
      "1m 21s (- 0m 6s) (11999 92%) 0.54243\n",
      "Loss: 0.7629552379775758\n",
      "Bleu score: 0.5072888534262027\n",
      "Epochs: 7\n",
      "1m 21s (- 0m 6s) (11999 92%) 0.48764\n",
      "Loss: 0.6776485935095663\n",
      "Bleu score: 0.5761383252440081\n",
      "Epochs: 8\n",
      "1m 21s (- 0m 6s) (11999 92%) 0.41867\n",
      "Loss: 0.5919852122763174\n",
      "Bleu score: 0.5941083247910874\n",
      "Epochs: 9\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.36162\n",
      "Loss: 0.5128570270607676\n",
      "Bleu score: 0.632414997768545\n",
      "Epochs: 10\n",
      "1m 21s (- 0m 6s) (11999 92%) 0.31742\n",
      "Loss: 0.43825856736462915\n",
      "Bleu score: 0.6687130158436841\n",
      "Epochs: 11\n",
      "1m 21s (- 0m 6s) (11999 92%) 0.27468\n",
      "Loss: 0.3722848526978707\n",
      "Bleu score: 0.6431272200628401\n",
      "Epochs: 12\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.23910\n",
      "Loss: 0.31791236487818386\n",
      "Bleu score: 0.6666373502789199\n",
      "Epochs: 13\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.22665\n",
      "Loss: 0.26472071403169894\n",
      "Bleu score: 0.7429426757248053\n",
      "Epochs: 14\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.22957\n",
      "Loss: 0.23101412052027304\n",
      "Bleu score: 0.690609255071219\n",
      "Epochs: 15\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.22364\n",
      "Loss: 0.19990446245729654\n",
      "Bleu score: 0.7124806050637084\n",
      "Epochs: 16\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.21808\n",
      "Loss: 0.183835646844835\n",
      "Bleu score: 0.7445081277032098\n",
      "Epochs: 17\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.21381\n",
      "Loss: 0.16979179186463442\n",
      "Bleu score: 0.7527140154186572\n",
      "Epochs: 18\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.20779\n",
      "Loss: 0.15750820672788646\n",
      "Bleu score: 0.755632119720695\n",
      "Epochs: 19\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.19903\n",
      "Loss: 0.1489637730679362\n",
      "Bleu score: 0.785528888146369\n",
      "Epochs: 20\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.18660\n",
      "Loss: 0.14245574518737558\n",
      "Bleu score: 0.8198926386997987\n",
      "Epochs: 21\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.18838\n",
      "Loss: 0.14120459320521503\n",
      "Bleu score: 0.7978208768659961\n",
      "Epochs: 22\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.16371\n",
      "Loss: 0.1307490734383274\n",
      "Bleu score: 0.8150022413711011\n",
      "Epochs: 23\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.17866\n",
      "Loss: 0.13576641908582937\n",
      "Bleu score: 0.8055424900229804\n",
      "Epochs: 24\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.18252\n",
      "Loss: 0.13149855955754713\n",
      "Bleu score: 0.7842346254632285\n",
      "Epochs: 25\n",
      "1m 21s (- 0m 6s) (11999 92%) 0.17568\n",
      "Loss: 0.13000569642026685\n",
      "Bleu score: 0.8272106825976182\n",
      "Epochs: 26\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.18586\n",
      "Loss: 0.13225552092159318\n",
      "Bleu score: 0.8049028171110233\n",
      "Epochs: 27\n",
      "1m 21s (- 0m 6s) (11999 92%) 0.19423\n",
      "Loss: 0.13191062212033258\n",
      "Bleu score: 0.7652051747365158\n",
      "Epochs: 28\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.17624\n",
      "Loss: 0.13264167359927667\n",
      "Bleu score: 0.8546848348880203\n",
      "Epochs: 29\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.17964\n",
      "Loss: 0.1322267336165738\n",
      "Bleu score: 0.8264421935799566\n",
      "Epochs: 30\n",
      "1m 23s (- 0m 6s) (11999 92%) 0.16394\n",
      "Loss: 0.12869256549576324\n",
      "Bleu score: 0.8588420156072207\n",
      "Epochs: 31\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.17384\n",
      "Loss: 0.12646660680553132\n",
      "Bleu score: 0.8588514208464977\n",
      "Epochs: 32\n",
      "1m 21s (- 0m 6s) (11999 92%) 0.17825\n",
      "Loss: 0.1252596753224808\n",
      "Bleu score: 0.8147794915852399\n",
      "Epochs: 33\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.16708\n",
      "Loss: 0.12889530202022526\n",
      "Bleu score: 0.8355245430467366\n",
      "Epochs: 34\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.17149\n",
      "Loss: 0.1268678189467833\n",
      "Bleu score: 0.8654341854954404\n",
      "Epochs: 35\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.15952\n",
      "Loss: 0.12058360976444227\n",
      "Bleu score: 0.8631417051629281\n",
      "Epochs: 36\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.16051\n",
      "Loss: 0.12397519272448339\n",
      "Bleu score: 0.8876007868846567\n",
      "Epochs: 37\n",
      "1m 21s (- 0m 6s) (11999 92%) 0.16591\n",
      "Loss: 0.11861549692229467\n",
      "Bleu score: 0.8908631211136914\n",
      "Epochs: 38\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.16770\n",
      "Loss: 0.1226792608400869\n",
      "Bleu score: 0.8848084698682572\n",
      "Epochs: 39\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.16437\n",
      "Loss: 0.12221433610289877\n",
      "Bleu score: 0.9033556283057587\n",
      "Epochs: 40\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.17822\n",
      "Loss: 0.11946651678159327\n",
      "Bleu score: 0.9190714624642757\n",
      "Epochs: 41\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.16721\n",
      "Loss: 0.12012532987762135\n",
      "Bleu score: 0.9264127416278177\n",
      "Epochs: 42\n",
      "1m 23s (- 0m 6s) (11999 92%) 0.15391\n",
      "Loss: 0.11701019675880418\n",
      "Bleu score: 0.8833046739771957\n",
      "Epochs: 43\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.15918\n",
      "Loss: 0.11642005252758317\n",
      "Bleu score: 0.9137426785478666\n",
      "Epochs: 44\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.14744\n",
      "Loss: 0.11504086548803198\n",
      "Bleu score: 0.9264088449826816\n",
      "Epochs: 45\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.16004\n",
      "Loss: 0.11744593622408377\n",
      "Bleu score: 0.9042884202114624\n",
      "Epochs: 46\n",
      "1m 23s (- 0m 6s) (11999 92%) 0.15626\n",
      "Loss: 0.1137406618945874\n",
      "Bleu score: 0.9498328293379495\n",
      "Epochs: 47\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.16090\n",
      "Loss: 0.1153939010462382\n",
      "Bleu score: 0.9186533985388836\n",
      "Epochs: 48\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.14454\n",
      "Loss: 0.11685541890932517\n",
      "Bleu score: 0.9192581026573127\n",
      "Epochs: 49\n",
      "1m 22s (- 0m 6s) (11999 92%) 0.13891\n",
      "Loss: 0.11903401599653624\n",
      "Bleu score: 0.9010627622226609\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    print(f\"Epochs: {i}\")\n",
    "    trainIters(data_list, label_list, encoder1, decoder1, len(data_list), plot_history=plot_history)\n",
    "    bleu_score = Evaluate_bleu(test_data_list, test_label_list, encoder1, decoder1)\n",
    "    print(f\"Bleu score: {bleu_score}\")\n",
    "    bleu_history.append(bleu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ece3092b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d', 'e', 'c', 'e', 'n', 't', 'EOS']\n"
     ]
    }
   ],
   "source": [
    "word_idx = 30\n",
    "using_data = test_data_list\n",
    "using_label = test_label_list\n",
    "with torch.no_grad():\n",
    "    init_hid = encoder1.initHidden()\n",
    "    out, hid = encoder1(using_data[word_idx].to(device), init_hid)\n",
    "    dec_hid = hid\n",
    "    dec_in = torch.tensor([SOS_token], device=device)\n",
    "    generated_word = []\n",
    "#     for i in range(len(using_label[word_idx])):\n",
    "    while True:\n",
    "        dec_out, dec_hid = decoder1(dec_in, dec_hid)\n",
    "        generated_word.append(index2char[dec_out.argmax(dim=2).item()])\n",
    "        dec_in = dec_out.argmax(dim=2).view(1,)\n",
    "        if dec_in.item() == EOS_token:\n",
    "            break\n",
    "    print(generated_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ff88f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d', 'e', 'c', 'e', 'n', 't', 'EOS']\n"
     ]
    }
   ],
   "source": [
    "target_word = []\n",
    "for i in range(len(using_label[word_idx])):\n",
    "    target_word.append(index2char[using_label[word_idx][i].item()])\n",
    "print(target_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bbc6468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_bleu(generated_word, target_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03b75993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.8997480002440437, 1.4808628321279897, 1.2197327714804789, 1.0731065150832484, 0.9605037884187603, 0.8612166672532952, 0.7629552379775758, 0.6776485935095663, 0.5919852122763174, 0.5128570270607676, 0.43825856736462915, 0.3722848526978707, 0.31791236487818386, 0.26472071403169894, 0.23101412052027304, 0.19990446245729654, 0.183835646844835, 0.16979179186463442, 0.15750820672788646, 0.1489637730679362, 0.14245574518737558, 0.14120459320521503, 0.1307490734383274, 0.13576641908582937, 0.13149855955754713, 0.13000569642026685, 0.13225552092159318, 0.13191062212033258, 0.13264167359927667, 0.1322267336165738, 0.12869256549576324, 0.12646660680553132, 0.1252596753224808, 0.12889530202022526, 0.1268678189467833, 0.12058360976444227, 0.12397519272448339, 0.11861549692229467, 0.1226792608400869, 0.12221433610289877, 0.11946651678159327, 0.12012532987762135, 0.11701019675880418, 0.11642005252758317, 0.11504086548803198, 0.11744593622408377, 0.1137406618945874, 0.1153939010462382, 0.11685541890932517, 0.11903401599653624]\n"
     ]
    }
   ],
   "source": [
    "print(plot_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95ba743f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11793764342129111, 0.2172421899996778, 0.2952050876902603, 0.41156354571503223, 0.4706009144508546, 0.49993660401800905, 0.5072888534262027, 0.5761383252440081, 0.5941083247910874, 0.632414997768545, 0.6687130158436841, 0.6431272200628401, 0.6666373502789199, 0.7429426757248053, 0.690609255071219, 0.7124806050637084, 0.7445081277032098, 0.7527140154186572, 0.755632119720695, 0.785528888146369, 0.8198926386997987, 0.7978208768659961, 0.8150022413711011, 0.8055424900229804, 0.7842346254632285, 0.8272106825976182, 0.8049028171110233, 0.7652051747365158, 0.8546848348880203, 0.8264421935799566, 0.8588420156072207, 0.8588514208464977, 0.8147794915852399, 0.8355245430467366, 0.8654341854954404, 0.8631417051629281, 0.8876007868846567, 0.8908631211136914, 0.8848084698682572, 0.9033556283057587, 0.9190714624642757, 0.9264127416278177, 0.8833046739771957, 0.9137426785478666, 0.9264088449826816, 0.9042884202114624, 0.9498328293379495, 0.9186533985388836, 0.9192581026573127, 0.9010627622226609]\n"
     ]
    }
   ],
   "source": [
    "print(bleu_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d09208ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb7e0de89d0>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(50)\n",
    "# plt.plot(x, plot_history)\n",
    "plt.plot(x, bleu_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d05bee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6779697917276644"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Evaluate_bleu(new_test_data_list, new_test_label_list, encoder1, decoder1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
