{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f0c3f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load CNN_MNIST_pytorch.py\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# 設置seed\n",
    "seed = 198964\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "# Dataloader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./MNIST_data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=128, shuffle=True, num_workers = 3)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./MNIST_data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=1000, shuffle=True,num_workers = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e2749d",
   "metadata": {},
   "source": [
    "增加兩行convolution layers，並增加neuron數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23169ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Network, we implement LeNet here\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=(5,5),stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(6, 6, kernel_size=(3,3),stride=1, padding=1) #add two convolution layers\n",
    "        self.conv3 = nn.Conv2d(6, 6, kernel_size=(3,3),stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(6, 16, kernel_size=(5,5),stride=1, padding=0)\n",
    "        self.fc1 = nn.Linear(16*4*4, 240) # make neuron 2x wider\n",
    "        self.fc2 = nn.Linear(240, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "#         out = F.max_pool2d(out, 2) <- no need to max pool because input size isn't big enough\n",
    "        out = F.relu(self.conv3(out))\n",
    "#         out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv4(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1) #flatten\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dac71fb",
   "metadata": {},
   "source": [
    "建model並設置優化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "537e2d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net() # build model\n",
    "if args.cuda:\n",
    "    device = torch.device('cuda')\n",
    "    model.to(device)\n",
    "\n",
    "#define optimizer/loss function\n",
    "Loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# select your optimizer, here we choose RMSprop because the original code performs badly in RMSprop, so I try to fix it.\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.1, momentum=0, alpha=0.5) # Learning rate here will be replaced by next function. By the way, alpha is set to 0.99 defaultly, and I set it to 0.5 . I don't want any momentum as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eff77f3",
   "metadata": {},
   "source": [
    "設定learning rate的排程，使他在多個epoch之後逐漸降低"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da9a4fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning rate scheduling\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    if epoch < 5: # After 5 epochs, everage loss always decrease slowly, so we can use smaller learning rate to avoid too much change\n",
    "        lr = 0.005  # 0.01 is too big so let's try 0.005\n",
    "    elif epoch < 15:\n",
    "        lr = 0.0005 \n",
    "    else: \n",
    "        lr = 0.00005\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e77a266",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [44928/60000 (100%)]\tLoss: 0.112505\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.5\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.005\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0680, Accuracy: 9791/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [44928/60000 (100%)]\tLoss: 0.038866\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.5\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.005\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0987, Accuracy: 9763/10000 (98%)\n",
      "\n",
      "Train Epoch: 3 [44928/60000 (100%)]\tLoss: 0.012791\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.5\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.005\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0829, Accuracy: 9826/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 [44928/60000 (100%)]\tLoss: 0.300899\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.5\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.005\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.1083, Accuracy: 9725/10000 (97%)\n",
      "\n",
      "Train Epoch: 5 [44928/60000 (100%)]\tLoss: 0.034954\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.5\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0406, Accuracy: 9890/10000 (99%)\n",
      "\n",
      "Train Epoch: 6 [44928/60000 (100%)]\tLoss: 0.032909\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.5\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0435, Accuracy: 9894/10000 (99%)\n",
      "\n",
      "Train Epoch: 7 [44928/60000 (100%)]\tLoss: 0.079101\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.5\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0438, Accuracy: 9890/10000 (99%)\n",
      "\n",
      "Train Epoch: 8 [44928/60000 (100%)]\tLoss: 0.008858\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.5\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0507, Accuracy: 9893/10000 (99%)\n",
      "\n",
      "Train Epoch: 9 [44928/60000 (100%)]\tLoss: 0.000633\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.5\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0529, Accuracy: 9889/10000 (99%)\n",
      "\n",
      "Train Epoch: 10 [44928/60000 (100%)]\tLoss: 0.020986\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.5\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0492, Accuracy: 9903/10000 (99%)\n",
      "\n",
      "Train Epoch: 11 [44928/60000 (100%)]\tLoss: 0.000205\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.5\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0543, Accuracy: 9890/10000 (99%)\n",
      "\n",
      "Train Epoch: 12 [44928/60000 (100%)]\tLoss: 0.000365\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.5\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0538, Accuracy: 9891/10000 (99%)\n",
      "\n",
      "Train Epoch: 13 [44928/60000 (100%)]\tLoss: 0.004979\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.5\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0509, Accuracy: 9886/10000 (99%)\n",
      "\n",
      "Train Epoch: 14 [44928/60000 (100%)]\tLoss: 0.029048\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.5\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0603, Accuracy: 9890/10000 (99%)\n",
      "\n",
      "Train Epoch: 15 [44928/60000 (100%)]\tLoss: 0.062927\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.5\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 5e-05\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0548, Accuracy: 9894/10000 (99%)\n",
      "\n",
      "Train Epoch: 16 [44928/60000 (100%)]\tLoss: 0.033539\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.5\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 5e-05\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0547, Accuracy: 9895/10000 (99%)\n",
      "\n",
      "Train Epoch: 17 [44928/60000 (100%)]\tLoss: 0.000365\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.5\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 5e-05\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0552, Accuracy: 9889/10000 (99%)\n",
      "\n",
      "Train Epoch: 18 [44928/60000 (100%)]\tLoss: 0.001004\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.5\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 5e-05\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0569, Accuracy: 9893/10000 (99%)\n",
      "\n",
      "Train Epoch: 19 [44928/60000 (100%)]\tLoss: 0.045953\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.5\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 5e-05\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0561, Accuracy: 9895/10000 (99%)\n",
      "\n",
      "Train Epoch: 20 [44928/60000 (100%)]\tLoss: 0.002858\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.5\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 5e-05\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "Test set: Average loss: 0.0601, Accuracy: 9893/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#training function\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if args.cuda:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = Loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "#Testing function\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        if args.cuda:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "            test_loss += Loss(output, target).item()\n",
    "            pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data).cpu().sum()\n",
    "\n",
    "    test_loss = test_loss\n",
    "    test_loss /= len(test_loader) # loss function already averages over batch size\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "#run and save model\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fbfeba-362b-4c28-a03f-6d1f4b371221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
