{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43313c5a-eaac-4625-99ab-fe476cfded0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "65722e19-652e-4cf8-81b5-deb61e094708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "197fd4d9-d2fd-4f77-8ddb-ae5220e34798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設置seed\n",
    "seed = 198964\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0c35a5a6-0f30-4755-80a0-a557eac12f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "train_data = datasets.MNIST('./MNIST_data', train=True, download=True,\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,))\n",
    "                            ]))\n",
    "test_data = datasets.MNIST('./MNIST_data', train=False, download=True,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.1307,),(0.3081,))\n",
    "                           ]))\n",
    "val_data, test_data = torch.utils.data.random_split(dataset=test_data, lengths=[5000,5000]) # 將test分成validation和test，validation用來驗證model，test最後用於測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a35ba60a-a5df-4dde-97c4-638a68c43758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True, num_workers=3)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=1000, shuffle=True, num_workers=3)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1000, shuffle=True, num_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "35ff4a38-3e9f-4ca0-90c8-58cfe960b4ca",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#training function\n",
    "def train(model, loss_func, data_loader, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0.\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_func(output, target)\n",
    "        train_loss +=  loss.item()\n",
    "        pred = output.argmax(dim=1) # dim 0 是一個batch內資料的數量，所以從dim 1取最大值的index\n",
    "        correct += pred.eq(target).sum() # 若index跟target一樣會表示成true，sum會把true當作1並加起來\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss /= len(data_loader)\n",
    "    correct /= len(data_loader.dataset)\n",
    "    print(f'Training Loss: {train_loss:.4f}, Accuracy: {100. * correct:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c49579c6-81d1-4218-a964-54a313016156",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Testing function\n",
    "def evaluate(model, loss_func, data_loader, val=True):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0.\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "            test_loss += loss_func(output, target).item()\n",
    "            pred = output.argmax(dim=1) \n",
    "            correct += pred.eq(target).sum()\n",
    "\n",
    "    test_loss /= len(data_loader)\n",
    "    correct /= len(data_loader.dataset)\n",
    "    if val: # 若val=False則改印test的訊息\n",
    "        print(f'Validation Loss: {test_loss:.4f}, Accuracy: {100. * correct:.2f}%\\n')\n",
    "    else:\n",
    "        print(f'Test Loss: {test_loss:.4f}, Accuracy: {100. * correct:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5834d123-5560-4bc1-bf54-d2a02a3b7c87",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Optimizer: SGD<br>\n",
    "備註：如果訓練顯示訊息太長可以右鍵點選\"Enable Scrolling for Output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e5bf08-4f82-4d66-aa3d-565094ec5f12",
   "metadata": {},
   "source": [
    "## Vanilla version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "23169ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=(5,5),stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=(5,5),stride=1, padding=0)\n",
    "        self.fc1 = nn.Linear(16*4*4, 120) \n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = torch.flatten(out, start_dim=1) \n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d56d19f2-1500-4376-b70f-2351e87a256c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 1\n",
      "Training Loss: 0.4733, Accuracy: 85.20%\n",
      "Validation Loss: 0.0691, Accuracy: 97.84%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 2\n",
      "Training Loss: 0.0775, Accuracy: 97.60%\n",
      "Validation Loss: 0.0463, Accuracy: 98.68%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 3\n",
      "Training Loss: 0.0566, Accuracy: 98.23%\n",
      "Validation Loss: 0.0405, Accuracy: 98.84%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 4\n",
      "Training Loss: 0.0447, Accuracy: 98.58%\n",
      "Validation Loss: 0.0335, Accuracy: 98.88%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 5\n",
      "Training Loss: 0.0367, Accuracy: 98.82%\n",
      "Validation Loss: 0.0311, Accuracy: 99.06%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 6\n",
      "Training Loss: 0.0319, Accuracy: 99.00%\n",
      "Validation Loss: 0.0287, Accuracy: 99.12%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 7\n",
      "Training Loss: 0.0275, Accuracy: 99.08%\n",
      "Validation Loss: 0.0327, Accuracy: 98.84%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 8\n",
      "Training Loss: 0.0239, Accuracy: 99.23%\n",
      "Validation Loss: 0.0250, Accuracy: 99.30%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 9\n",
      "Training Loss: 0.0197, Accuracy: 99.34%\n",
      "Validation Loss: 0.0241, Accuracy: 99.28%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 10\n",
      "Training Loss: 0.0177, Accuracy: 99.42%\n",
      "Validation Loss: 0.0289, Accuracy: 99.20%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 11\n",
      "Training Loss: 0.0097, Accuracy: 99.71%\n",
      "Validation Loss: 0.0205, Accuracy: 99.36%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 12\n",
      "Training Loss: 0.0080, Accuracy: 99.81%\n",
      "Validation Loss: 0.0196, Accuracy: 99.40%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 13\n",
      "Training Loss: 0.0073, Accuracy: 99.82%\n",
      "Validation Loss: 0.0195, Accuracy: 99.46%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 14\n",
      "Training Loss: 0.0069, Accuracy: 99.82%\n",
      "Validation Loss: 0.0205, Accuracy: 99.36%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 15\n",
      "Training Loss: 0.0066, Accuracy: 99.84%\n",
      "Validation Loss: 0.0193, Accuracy: 99.46%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 16\n",
      "Training Loss: 0.0064, Accuracy: 99.85%\n",
      "Validation Loss: 0.0195, Accuracy: 99.44%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 17\n",
      "Training Loss: 0.0061, Accuracy: 99.86%\n",
      "Validation Loss: 0.0202, Accuracy: 99.38%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 18\n",
      "Training Loss: 0.0059, Accuracy: 99.86%\n",
      "Validation Loss: 0.0199, Accuracy: 99.40%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 19\n",
      "Training Loss: 0.0057, Accuracy: 99.89%\n",
      "Validation Loss: 0.0193, Accuracy: 99.38%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 20\n",
      "Training Loss: 0.0055, Accuracy: 99.88%\n",
      "Validation Loss: 0.0197, Accuracy: 99.40%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Test Loss: 0.0307, Accuracy: 99.02%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start training model\n",
    "model = Net().to(device) # build model\n",
    "epochs = 20\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.01, momentum=0.9)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=10, gamma=0.1, verbose=True)\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: {epoch+1}')\n",
    "    train(model, loss_func, train_loader, optimizer)\n",
    "    evaluate(model, loss_func, val_loader, val=True)\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "evaluate(model, loss_func, test_loader, val=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675172fa-0ca5-431f-97dc-9e0526637c1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Insert two 3x3 convolution layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a8b93078-3694-4c3a-be1e-27f59a39bfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module with two more layers\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=(5,5),stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(6, 6, kernel_size=(3,3),stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(6, 6, kernel_size=(3,3),stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(6, 16, kernel_size=(5,5),stride=1, padding=0)\n",
    "        self.fc1 = nn.Linear(16*4*4, 120) # make neuron 2x wider\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv3(out))\n",
    "        out = F.relu(self.conv4(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = torch.flatten(out, start_dim=1) #flatten\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "90568edf-96df-476b-9bd1-885617e3f9e7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 1\n",
      "Training Loss: 0.9278, Accuracy: 66.73%\n",
      "Validation Loss: 0.1085, Accuracy: 96.38%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 2\n",
      "Training Loss: 0.1078, Accuracy: 96.68%\n",
      "Validation Loss: 0.0928, Accuracy: 97.14%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 3\n",
      "Training Loss: 0.0747, Accuracy: 97.68%\n",
      "Validation Loss: 0.0618, Accuracy: 97.96%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 4\n",
      "Training Loss: 0.0589, Accuracy: 98.18%\n",
      "Validation Loss: 0.0517, Accuracy: 98.38%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 5\n",
      "Training Loss: 0.0483, Accuracy: 98.48%\n",
      "Validation Loss: 0.0441, Accuracy: 98.78%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 6\n",
      "Training Loss: 0.0403, Accuracy: 98.74%\n",
      "Validation Loss: 0.0446, Accuracy: 98.70%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 7\n",
      "Training Loss: 0.0347, Accuracy: 98.91%\n",
      "Validation Loss: 0.0468, Accuracy: 98.48%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 8\n",
      "Training Loss: 0.0298, Accuracy: 99.06%\n",
      "Validation Loss: 0.0467, Accuracy: 98.56%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 9\n",
      "Training Loss: 0.0272, Accuracy: 99.13%\n",
      "Validation Loss: 0.0375, Accuracy: 98.92%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 10\n",
      "Training Loss: 0.0247, Accuracy: 99.20%\n",
      "Validation Loss: 0.0373, Accuracy: 98.94%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 11\n",
      "Training Loss: 0.0121, Accuracy: 99.67%\n",
      "Validation Loss: 0.0314, Accuracy: 99.16%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 12\n",
      "Training Loss: 0.0097, Accuracy: 99.74%\n",
      "Validation Loss: 0.0317, Accuracy: 99.12%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 13\n",
      "Training Loss: 0.0087, Accuracy: 99.76%\n",
      "Validation Loss: 0.0319, Accuracy: 99.12%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 14\n",
      "Training Loss: 0.0080, Accuracy: 99.80%\n",
      "Validation Loss: 0.0320, Accuracy: 99.12%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 15\n",
      "Training Loss: 0.0075, Accuracy: 99.81%\n",
      "Validation Loss: 0.0323, Accuracy: 99.08%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 16\n",
      "Training Loss: 0.0070, Accuracy: 99.82%\n",
      "Validation Loss: 0.0325, Accuracy: 99.08%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 17\n",
      "Training Loss: 0.0066, Accuracy: 99.84%\n",
      "Validation Loss: 0.0330, Accuracy: 99.18%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 18\n",
      "Training Loss: 0.0061, Accuracy: 99.86%\n",
      "Validation Loss: 0.0348, Accuracy: 98.96%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 19\n",
      "Training Loss: 0.0058, Accuracy: 99.87%\n",
      "Validation Loss: 0.0342, Accuracy: 99.10%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 20\n",
      "Training Loss: 0.0055, Accuracy: 99.88%\n",
      "Validation Loss: 0.0338, Accuracy: 99.10%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Test Loss: 0.0448, Accuracy: 98.86%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start training model\n",
    "model = Net().to(device) # build model\n",
    "epochs = 20\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.01, momentum=0.9)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=10, gamma=0.1, verbose=True)\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: {epoch+1}')\n",
    "    train(model, loss_func, train_loader, optimizer)\n",
    "    evaluate(model, loss_func, val_loader, val=True)\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "evaluate(model, loss_func, test_loader, val=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4dcf49-ff72-4544-ac94-dd41feb992f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2x more neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3bdb023d-b9bb-4638-99a0-e9d831962890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module with 2x more neuron\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=(5,5),stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=(5,5),stride=1, padding=0)\n",
    "        self.fc1 = nn.Linear(16*4*4, 240) \n",
    "        self.fc2 = nn.Linear(240, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = torch.flatten(out, start_dim=1) \n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "736fcc9a-514f-48d3-9ea3-29d0fd2bef90",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 1\n",
      "Training Loss: 0.9278, Accuracy: 66.73%\n",
      "Validation Loss: 0.1085, Accuracy: 96.38%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 2\n",
      "Training Loss: 0.1078, Accuracy: 96.68%\n",
      "Validation Loss: 0.0928, Accuracy: 97.14%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 3\n",
      "Training Loss: 0.0747, Accuracy: 97.68%\n",
      "Validation Loss: 0.0618, Accuracy: 97.96%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 4\n",
      "Training Loss: 0.0589, Accuracy: 98.18%\n",
      "Validation Loss: 0.0517, Accuracy: 98.38%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 5\n",
      "Training Loss: 0.0483, Accuracy: 98.48%\n",
      "Validation Loss: 0.0441, Accuracy: 98.78%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 6\n",
      "Training Loss: 0.0403, Accuracy: 98.74%\n",
      "Validation Loss: 0.0446, Accuracy: 98.70%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 7\n",
      "Training Loss: 0.0347, Accuracy: 98.91%\n",
      "Validation Loss: 0.0468, Accuracy: 98.48%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 8\n",
      "Training Loss: 0.0298, Accuracy: 99.06%\n",
      "Validation Loss: 0.0467, Accuracy: 98.56%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 9\n",
      "Training Loss: 0.0272, Accuracy: 99.13%\n",
      "Validation Loss: 0.0375, Accuracy: 98.92%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 10\n",
      "Training Loss: 0.0247, Accuracy: 99.20%\n",
      "Validation Loss: 0.0373, Accuracy: 98.94%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 11\n",
      "Training Loss: 0.0121, Accuracy: 99.67%\n",
      "Validation Loss: 0.0314, Accuracy: 99.16%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 12\n",
      "Training Loss: 0.0097, Accuracy: 99.74%\n",
      "Validation Loss: 0.0317, Accuracy: 99.12%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 13\n",
      "Training Loss: 0.0087, Accuracy: 99.76%\n",
      "Validation Loss: 0.0319, Accuracy: 99.12%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 14\n",
      "Training Loss: 0.0080, Accuracy: 99.80%\n",
      "Validation Loss: 0.0320, Accuracy: 99.12%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 15\n",
      "Training Loss: 0.0075, Accuracy: 99.81%\n",
      "Validation Loss: 0.0323, Accuracy: 99.08%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 16\n",
      "Training Loss: 0.0070, Accuracy: 99.82%\n",
      "Validation Loss: 0.0325, Accuracy: 99.08%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 17\n",
      "Training Loss: 0.0066, Accuracy: 99.84%\n",
      "Validation Loss: 0.0330, Accuracy: 99.18%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 18\n",
      "Training Loss: 0.0061, Accuracy: 99.86%\n",
      "Validation Loss: 0.0348, Accuracy: 98.96%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 19\n",
      "Training Loss: 0.0058, Accuracy: 99.87%\n",
      "Validation Loss: 0.0342, Accuracy: 99.10%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 20\n",
      "Training Loss: 0.0055, Accuracy: 99.88%\n",
      "Validation Loss: 0.0338, Accuracy: 99.10%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Test Loss: 0.0448, Accuracy: 98.86%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start training model\n",
    "model = Net().to(device) # build model\n",
    "epochs = 20\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.01, momentum=0.9)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=10, gamma=0.1, verbose=True)\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: {epoch+1}')\n",
    "    train(model, loss_func, train_loader, optimizer)\n",
    "    evaluate(model, loss_func, val_loader, val=True)\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "evaluate(model, loss_func, test_loader, val=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec34239-f550-46f9-b403-b052f139d825",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Optimizer: Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15ee98a-b952-4d01-8c3e-3f29eebeb0ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Vanilla version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c64f10d6-28ca-46f6-9115-7edc5b3123c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=(5,5),stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=(5,5),stride=1, padding=0)\n",
    "        self.fc1 = nn.Linear(16*4*4, 120) \n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = torch.flatten(out, start_dim=1) \n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "54aff608-5a2d-4bc3-88da-53d9311f0ee8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 1\n",
      "Training Loss: 0.1728, Accuracy: 94.70%\n",
      "Validation Loss: 0.0811, Accuracy: 97.64%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 2\n",
      "Training Loss: 0.0789, Accuracy: 97.83%\n",
      "Validation Loss: 0.0761, Accuracy: 97.66%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 3\n",
      "Training Loss: 0.0687, Accuracy: 98.16%\n",
      "Validation Loss: 0.0497, Accuracy: 98.54%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 4\n",
      "Training Loss: 0.0669, Accuracy: 98.25%\n",
      "Validation Loss: 0.0761, Accuracy: 97.92%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 5\n",
      "Training Loss: 0.0610, Accuracy: 98.45%\n",
      "Validation Loss: 0.0657, Accuracy: 97.90%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 6\n",
      "Training Loss: 0.0682, Accuracy: 98.32%\n",
      "Validation Loss: 0.0620, Accuracy: 98.44%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 7\n",
      "Training Loss: 0.0578, Accuracy: 98.59%\n",
      "Validation Loss: 0.0586, Accuracy: 98.70%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 8\n",
      "Training Loss: 0.0546, Accuracy: 98.68%\n",
      "Validation Loss: 0.0512, Accuracy: 98.60%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 9\n",
      "Training Loss: 0.0615, Accuracy: 98.55%\n",
      "Validation Loss: 0.0660, Accuracy: 98.38%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 10\n",
      "Training Loss: 0.0690, Accuracy: 98.45%\n",
      "Validation Loss: 0.1062, Accuracy: 98.20%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 11\n",
      "Training Loss: 0.0295, Accuracy: 99.27%\n",
      "Validation Loss: 0.0554, Accuracy: 98.78%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 12\n",
      "Training Loss: 0.0165, Accuracy: 99.52%\n",
      "Validation Loss: 0.0530, Accuracy: 98.90%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 13\n",
      "Training Loss: 0.0122, Accuracy: 99.64%\n",
      "Validation Loss: 0.0528, Accuracy: 98.90%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 14\n",
      "Training Loss: 0.0096, Accuracy: 99.72%\n",
      "Validation Loss: 0.0570, Accuracy: 98.92%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 15\n",
      "Training Loss: 0.0080, Accuracy: 99.77%\n",
      "Validation Loss: 0.0541, Accuracy: 99.00%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 16\n",
      "Training Loss: 0.0066, Accuracy: 99.81%\n",
      "Validation Loss: 0.0581, Accuracy: 99.04%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 17\n",
      "Training Loss: 0.0053, Accuracy: 99.83%\n",
      "Validation Loss: 0.0594, Accuracy: 99.02%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 18\n",
      "Training Loss: 0.0044, Accuracy: 99.86%\n",
      "Validation Loss: 0.0620, Accuracy: 99.04%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 19\n",
      "Training Loss: 0.0036, Accuracy: 99.89%\n",
      "Validation Loss: 0.0627, Accuracy: 99.06%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 20\n",
      "Training Loss: 0.0033, Accuracy: 99.90%\n",
      "Validation Loss: 0.0698, Accuracy: 99.02%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Test Loss: 0.0828, Accuracy: 98.86%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start training model\n",
    "model = Net().to(device) # build model\n",
    "epochs = 20\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.01)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=10, gamma=0.1, verbose=True)\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: {epoch+1}')\n",
    "    train(model, loss_func, train_loader, optimizer)\n",
    "    evaluate(model, loss_func, val_loader, val=True)\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "evaluate(model, loss_func, test_loader, val=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aded35ea-7f46-4f1f-9d30-e69cd1f32df3",
   "metadata": {},
   "source": [
    "## Insert two 3x3 convolution layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2aa8f118-81f4-4713-a47a-526ad7f28226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module with two more layers\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=(5,5),stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(6, 6, kernel_size=(3,3),stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(6, 6, kernel_size=(3,3),stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(6, 16, kernel_size=(5,5),stride=1, padding=0)\n",
    "        self.fc1 = nn.Linear(16*4*4, 120) # make neuron 2x wider\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv3(out))\n",
    "        out = F.relu(self.conv4(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = torch.flatten(out, start_dim=1) #flatten\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4aa4cfcb-cc00-43a4-b167-0e3b456c7506",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 1\n",
      "Training Loss: 0.2347, Accuracy: 92.21%\n",
      "Validation Loss: 0.0667, Accuracy: 97.78%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 2\n",
      "Training Loss: 0.0875, Accuracy: 97.40%\n",
      "Validation Loss: 0.0635, Accuracy: 98.10%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 3\n",
      "Training Loss: 0.0783, Accuracy: 97.76%\n",
      "Validation Loss: 0.0563, Accuracy: 98.58%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 4\n",
      "Training Loss: 0.0717, Accuracy: 97.92%\n",
      "Validation Loss: 0.0996, Accuracy: 97.26%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 5\n",
      "Training Loss: 0.0680, Accuracy: 98.16%\n",
      "Validation Loss: 0.0766, Accuracy: 97.74%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 6\n",
      "Training Loss: 0.0744, Accuracy: 97.99%\n",
      "Validation Loss: 0.0925, Accuracy: 97.82%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 7\n",
      "Training Loss: 0.0715, Accuracy: 98.10%\n",
      "Validation Loss: 0.0546, Accuracy: 98.50%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 8\n",
      "Training Loss: 0.0680, Accuracy: 98.18%\n",
      "Validation Loss: 0.0768, Accuracy: 98.26%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 9\n",
      "Training Loss: 0.0627, Accuracy: 98.35%\n",
      "Validation Loss: 0.0779, Accuracy: 98.24%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 10\n",
      "Training Loss: 0.0665, Accuracy: 98.30%\n",
      "Validation Loss: 0.0994, Accuracy: 97.46%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 11\n",
      "Training Loss: 0.0370, Accuracy: 98.98%\n",
      "Validation Loss: 0.0372, Accuracy: 98.92%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 12\n",
      "Training Loss: 0.0223, Accuracy: 99.37%\n",
      "Validation Loss: 0.0335, Accuracy: 99.12%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 13\n",
      "Training Loss: 0.0173, Accuracy: 99.48%\n",
      "Validation Loss: 0.0364, Accuracy: 99.06%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 14\n",
      "Training Loss: 0.0142, Accuracy: 99.58%\n",
      "Validation Loss: 0.0354, Accuracy: 99.12%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 15\n",
      "Training Loss: 0.0120, Accuracy: 99.65%\n",
      "Validation Loss: 0.0379, Accuracy: 99.08%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 16\n",
      "Training Loss: 0.0103, Accuracy: 99.68%\n",
      "Validation Loss: 0.0402, Accuracy: 99.02%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 17\n",
      "Training Loss: 0.0084, Accuracy: 99.76%\n",
      "Validation Loss: 0.0392, Accuracy: 99.04%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 18\n",
      "Training Loss: 0.0075, Accuracy: 99.77%\n",
      "Validation Loss: 0.0403, Accuracy: 99.12%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 19\n",
      "Training Loss: 0.0062, Accuracy: 99.83%\n",
      "Validation Loss: 0.0443, Accuracy: 98.98%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 20\n",
      "Training Loss: 0.0053, Accuracy: 99.85%\n",
      "Validation Loss: 0.0459, Accuracy: 99.16%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Test Loss: 0.0952, Accuracy: 98.72%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start training model\n",
    "model = Net().to(device) # build model\n",
    "epochs = 20\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.01)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=10, gamma=0.1, verbose=True)\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: {epoch+1}')\n",
    "    train(model, loss_func, train_loader, optimizer)\n",
    "    evaluate(model, loss_func, val_loader, val=True)\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "evaluate(model, loss_func, test_loader, val=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab234b20-b719-4ce6-a1ad-71df661dba26",
   "metadata": {},
   "source": [
    "## 2x more neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8a2a754c-4a96-43aa-8292-505ae6a34b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module with 2x more neuron\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=(5,5),stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=(5,5),stride=1, padding=0)\n",
    "        self.fc1 = nn.Linear(16*4*4, 240) \n",
    "        self.fc2 = nn.Linear(240, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = torch.flatten(out, start_dim=1) \n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9edcdad9-883f-459b-8122-d67f347a3d41",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 1\n",
      "Training Loss: 0.1654, Accuracy: 94.96%\n",
      "Validation Loss: 0.0823, Accuracy: 97.42%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 2\n",
      "Training Loss: 0.0777, Accuracy: 97.81%\n",
      "Validation Loss: 0.0712, Accuracy: 98.14%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 3\n",
      "Training Loss: 0.0643, Accuracy: 98.23%\n",
      "Validation Loss: 0.0614, Accuracy: 98.46%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 4\n",
      "Training Loss: 0.0686, Accuracy: 98.19%\n",
      "Validation Loss: 0.0687, Accuracy: 98.12%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 5\n",
      "Training Loss: 0.0669, Accuracy: 98.26%\n",
      "Validation Loss: 0.0713, Accuracy: 98.28%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 6\n",
      "Training Loss: 0.0597, Accuracy: 98.47%\n",
      "Validation Loss: 0.0666, Accuracy: 98.50%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 7\n",
      "Training Loss: 0.0579, Accuracy: 98.58%\n",
      "Validation Loss: 0.0812, Accuracy: 98.20%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 8\n",
      "Training Loss: 0.0687, Accuracy: 98.40%\n",
      "Validation Loss: 0.0792, Accuracy: 98.48%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 9\n",
      "Training Loss: 0.0561, Accuracy: 98.62%\n",
      "Validation Loss: 0.0909, Accuracy: 98.46%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 10\n",
      "Training Loss: 0.0591, Accuracy: 98.60%\n",
      "Validation Loss: 0.0622, Accuracy: 98.40%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 11\n",
      "Training Loss: 0.0226, Accuracy: 99.40%\n",
      "Validation Loss: 0.0352, Accuracy: 99.12%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 12\n",
      "Training Loss: 0.0121, Accuracy: 99.67%\n",
      "Validation Loss: 0.0362, Accuracy: 99.26%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 13\n",
      "Training Loss: 0.0089, Accuracy: 99.75%\n",
      "Validation Loss: 0.0360, Accuracy: 99.16%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 14\n",
      "Training Loss: 0.0070, Accuracy: 99.80%\n",
      "Validation Loss: 0.0364, Accuracy: 99.30%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 15\n",
      "Training Loss: 0.0057, Accuracy: 99.83%\n",
      "Validation Loss: 0.0417, Accuracy: 99.22%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 16\n",
      "Training Loss: 0.0044, Accuracy: 99.87%\n",
      "Validation Loss: 0.0474, Accuracy: 99.20%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 17\n",
      "Training Loss: 0.0036, Accuracy: 99.89%\n",
      "Validation Loss: 0.0513, Accuracy: 99.20%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 18\n",
      "Training Loss: 0.0028, Accuracy: 99.90%\n",
      "Validation Loss: 0.0520, Accuracy: 99.18%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 19\n",
      "Training Loss: 0.0026, Accuracy: 99.90%\n",
      "Validation Loss: 0.0549, Accuracy: 99.20%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 20\n",
      "Training Loss: 0.0019, Accuracy: 99.93%\n",
      "Validation Loss: 0.0720, Accuracy: 99.10%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Test Loss: 0.0805, Accuracy: 98.90%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start training model\n",
    "model = Net().to(device) # build model\n",
    "epochs = 20\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.01)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=10, gamma=0.1, verbose=True)\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: {epoch+1}')\n",
    "    train(model, loss_func, train_loader, optimizer)\n",
    "    evaluate(model, loss_func, val_loader, val=True)\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "evaluate(model, loss_func, test_loader, val=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d3e574-4cbf-4320-b981-c4015410c055",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Optimizer: RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf31f01-5aa0-4b61-91ab-16fffce44730",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Vanilla version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6211b156-9e19-4c7d-928d-b5dd54f0ce3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=(5,5),stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=(5,5),stride=1, padding=0)\n",
    "        self.fc1 = nn.Linear(16*4*4, 120) \n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = torch.flatten(out, start_dim=1) \n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "eba6c4e4-e70c-4101-9ede-f7a009284256",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 1\n",
      "Training Loss: 0.3627, Accuracy: 88.93%\n",
      "Validation Loss: 0.0954, Accuracy: 96.90%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 2\n",
      "Training Loss: 0.0847, Accuracy: 97.35%\n",
      "Validation Loss: 0.0446, Accuracy: 98.62%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 3\n",
      "Training Loss: 0.0600, Accuracy: 98.13%\n",
      "Validation Loss: 0.0474, Accuracy: 98.32%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 4\n",
      "Training Loss: 0.0486, Accuracy: 98.49%\n",
      "Validation Loss: 0.0345, Accuracy: 98.90%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 5\n",
      "Training Loss: 0.0416, Accuracy: 98.78%\n",
      "Validation Loss: 0.0486, Accuracy: 98.62%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 6\n",
      "Training Loss: 0.0375, Accuracy: 98.88%\n",
      "Validation Loss: 0.0407, Accuracy: 98.92%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 7\n",
      "Training Loss: 0.0345, Accuracy: 98.98%\n",
      "Validation Loss: 0.0497, Accuracy: 98.72%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 8\n",
      "Training Loss: 0.0318, Accuracy: 99.10%\n",
      "Validation Loss: 0.0382, Accuracy: 98.92%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 9\n",
      "Training Loss: 0.0299, Accuracy: 99.11%\n",
      "Validation Loss: 0.0473, Accuracy: 98.82%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 10\n",
      "Training Loss: 0.0288, Accuracy: 99.23%\n",
      "Validation Loss: 0.0474, Accuracy: 98.82%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 11\n",
      "Training Loss: 0.0145, Accuracy: 99.63%\n",
      "Validation Loss: 0.0367, Accuracy: 99.00%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 12\n",
      "Training Loss: 0.0121, Accuracy: 99.69%\n",
      "Validation Loss: 0.0379, Accuracy: 99.02%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 13\n",
      "Training Loss: 0.0113, Accuracy: 99.72%\n",
      "Validation Loss: 0.0398, Accuracy: 98.96%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 14\n",
      "Training Loss: 0.0108, Accuracy: 99.74%\n",
      "Validation Loss: 0.0415, Accuracy: 98.98%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 15\n",
      "Training Loss: 0.0106, Accuracy: 99.73%\n",
      "Validation Loss: 0.0407, Accuracy: 99.04%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 16\n",
      "Training Loss: 0.0104, Accuracy: 99.74%\n",
      "Validation Loss: 0.0398, Accuracy: 99.00%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 17\n",
      "Training Loss: 0.0101, Accuracy: 99.76%\n",
      "Validation Loss: 0.0422, Accuracy: 99.04%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 18\n",
      "Training Loss: 0.0098, Accuracy: 99.76%\n",
      "Validation Loss: 0.0425, Accuracy: 99.02%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 19\n",
      "Training Loss: 0.0094, Accuracy: 99.78%\n",
      "Validation Loss: 0.0420, Accuracy: 99.08%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 20\n",
      "Training Loss: 0.0093, Accuracy: 99.78%\n",
      "Validation Loss: 0.0443, Accuracy: 99.06%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Test Loss: 0.0466, Accuracy: 99.06%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start training model\n",
    "model = Net().to(device) # build model\n",
    "epochs = 20\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(),lr=0.001,alpha=0.5)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=10, gamma=0.1, verbose=True)\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: {epoch+1}')\n",
    "    train(model, loss_func, train_loader, optimizer)\n",
    "    evaluate(model, loss_func, val_loader, val=True)\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "evaluate(model, loss_func, test_loader, val=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e85f91-797f-49d9-ba0d-f2699d2ed3c9",
   "metadata": {},
   "source": [
    "## Insert two 3x3 convolution layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bc182688-ee82-482b-a8d5-227a1fcd808f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module with two more layers\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=(5,5),stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(6, 6, kernel_size=(3,3),stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(6, 6, kernel_size=(3,3),stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(6, 16, kernel_size=(5,5),stride=1, padding=0)\n",
    "        self.fc1 = nn.Linear(16*4*4, 120) # make neuron 2x wider\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv3(out))\n",
    "        out = F.relu(self.conv4(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = torch.flatten(out, start_dim=1) #flatten\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2d108702-3c3d-4932-b640-0dcf7a3f86ba",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 1\n",
      "Training Loss: 0.4352, Accuracy: 85.56%\n",
      "Validation Loss: 0.0829, Accuracy: 97.32%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 2\n",
      "Training Loss: 0.0830, Accuracy: 97.39%\n",
      "Validation Loss: 0.0636, Accuracy: 98.04%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 3\n",
      "Training Loss: 0.0576, Accuracy: 98.26%\n",
      "Validation Loss: 0.0487, Accuracy: 98.38%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 4\n",
      "Training Loss: 0.0466, Accuracy: 98.58%\n",
      "Validation Loss: 0.0370, Accuracy: 98.90%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 5\n",
      "Training Loss: 0.0402, Accuracy: 98.78%\n",
      "Validation Loss: 0.0372, Accuracy: 98.78%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 6\n",
      "Training Loss: 0.0352, Accuracy: 98.98%\n",
      "Validation Loss: 0.0410, Accuracy: 98.88%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 7\n",
      "Training Loss: 0.0319, Accuracy: 99.10%\n",
      "Validation Loss: 0.0324, Accuracy: 99.12%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 8\n",
      "Training Loss: 0.0289, Accuracy: 99.12%\n",
      "Validation Loss: 0.0372, Accuracy: 98.96%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 9\n",
      "Training Loss: 0.0266, Accuracy: 99.22%\n",
      "Validation Loss: 0.0346, Accuracy: 98.92%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 10\n",
      "Training Loss: 0.0262, Accuracy: 99.24%\n",
      "Validation Loss: 0.0379, Accuracy: 98.84%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 11\n",
      "Training Loss: 0.0135, Accuracy: 99.61%\n",
      "Validation Loss: 0.0281, Accuracy: 99.20%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 12\n",
      "Training Loss: 0.0117, Accuracy: 99.68%\n",
      "Validation Loss: 0.0295, Accuracy: 99.14%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 13\n",
      "Training Loss: 0.0113, Accuracy: 99.70%\n",
      "Validation Loss: 0.0269, Accuracy: 99.16%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 14\n",
      "Training Loss: 0.0108, Accuracy: 99.73%\n",
      "Validation Loss: 0.0285, Accuracy: 99.20%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 15\n",
      "Training Loss: 0.0104, Accuracy: 99.74%\n",
      "Validation Loss: 0.0313, Accuracy: 99.16%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 16\n",
      "Training Loss: 0.0102, Accuracy: 99.74%\n",
      "Validation Loss: 0.0318, Accuracy: 99.10%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 17\n",
      "Training Loss: 0.0098, Accuracy: 99.76%\n",
      "Validation Loss: 0.0337, Accuracy: 99.12%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 18\n",
      "Training Loss: 0.0095, Accuracy: 99.78%\n",
      "Validation Loss: 0.0323, Accuracy: 99.08%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 19\n",
      "Training Loss: 0.0094, Accuracy: 99.77%\n",
      "Validation Loss: 0.0355, Accuracy: 99.04%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 20\n",
      "Training Loss: 0.0091, Accuracy: 99.78%\n",
      "Validation Loss: 0.0343, Accuracy: 99.14%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Test Loss: 0.0440, Accuracy: 99.02%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start training model\n",
    "model = Net().to(device) # build model\n",
    "epochs = 20\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(),lr=0.001,alpha=0.5)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=10, gamma=0.1, verbose=True)\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: {epoch+1}')\n",
    "    train(model, loss_func, train_loader, optimizer)\n",
    "    evaluate(model, loss_func, val_loader, val=True)\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "evaluate(model, loss_func, test_loader, val=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222e7d74-a338-40c0-b83b-862e9db2b440",
   "metadata": {},
   "source": [
    "## 2x more neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3df98a22-3c82-4101-8a45-9f96f3fa92ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module with 2x more neuron\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=(5,5),stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=(5,5),stride=1, padding=0)\n",
    "        self.fc1 = nn.Linear(16*4*4, 240) \n",
    "        self.fc2 = nn.Linear(240, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = torch.flatten(out, start_dim=1) \n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a71a81b9-23b4-41fd-80c2-175da7509baa",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 1\n",
      "Training Loss: 0.3235, Accuracy: 90.08%\n",
      "Validation Loss: 0.0747, Accuracy: 97.48%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 2\n",
      "Training Loss: 0.0734, Accuracy: 97.71%\n",
      "Validation Loss: 0.0443, Accuracy: 98.68%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 3\n",
      "Training Loss: 0.0526, Accuracy: 98.41%\n",
      "Validation Loss: 0.0478, Accuracy: 98.58%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 4\n",
      "Training Loss: 0.0443, Accuracy: 98.67%\n",
      "Validation Loss: 0.0396, Accuracy: 98.90%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 5\n",
      "Training Loss: 0.0384, Accuracy: 98.88%\n",
      "Validation Loss: 0.0368, Accuracy: 99.00%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 6\n",
      "Training Loss: 0.0337, Accuracy: 99.02%\n",
      "Validation Loss: 0.0356, Accuracy: 99.14%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 7\n",
      "Training Loss: 0.0305, Accuracy: 99.14%\n",
      "Validation Loss: 0.0450, Accuracy: 98.92%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 8\n",
      "Training Loss: 0.0284, Accuracy: 99.20%\n",
      "Validation Loss: 0.0357, Accuracy: 98.78%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 9\n",
      "Training Loss: 0.0265, Accuracy: 99.24%\n",
      "Validation Loss: 0.0424, Accuracy: 98.82%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 10\n",
      "Training Loss: 0.0254, Accuracy: 99.27%\n",
      "Validation Loss: 0.0387, Accuracy: 98.88%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 11\n",
      "Training Loss: 0.0111, Accuracy: 99.70%\n",
      "Validation Loss: 0.0301, Accuracy: 99.26%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 12\n",
      "Training Loss: 0.0095, Accuracy: 99.76%\n",
      "Validation Loss: 0.0332, Accuracy: 99.22%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 13\n",
      "Training Loss: 0.0091, Accuracy: 99.78%\n",
      "Validation Loss: 0.0311, Accuracy: 99.32%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 14\n",
      "Training Loss: 0.0086, Accuracy: 99.80%\n",
      "Validation Loss: 0.0337, Accuracy: 99.26%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 15\n",
      "Training Loss: 0.0080, Accuracy: 99.82%\n",
      "Validation Loss: 0.0330, Accuracy: 99.28%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 16\n",
      "Training Loss: 0.0077, Accuracy: 99.82%\n",
      "Validation Loss: 0.0349, Accuracy: 99.34%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 17\n",
      "Training Loss: 0.0075, Accuracy: 99.83%\n",
      "Validation Loss: 0.0331, Accuracy: 99.30%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 18\n",
      "Training Loss: 0.0074, Accuracy: 99.83%\n",
      "Validation Loss: 0.0344, Accuracy: 99.34%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 19\n",
      "Training Loss: 0.0072, Accuracy: 99.85%\n",
      "Validation Loss: 0.0334, Accuracy: 99.40%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 20\n",
      "Training Loss: 0.0069, Accuracy: 99.86%\n",
      "Validation Loss: 0.0351, Accuracy: 99.40%\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Test Loss: 0.0524, Accuracy: 98.92%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start training model\n",
    "model = Net().to(device) # build model\n",
    "epochs = 20\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(),lr=0.001,alpha=0.5)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=10, gamma=0.1, verbose=True)\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: {epoch+1}')\n",
    "    train(model, loss_func, train_loader, optimizer)\n",
    "    evaluate(model, loss_func, val_loader, val=True)\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "evaluate(model, loss_func, test_loader, val=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
