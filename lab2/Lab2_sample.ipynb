{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EuCYJSSDFukq"
   },
   "source": [
    "# Lab 2 Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "v0BmuW9dcCId"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import dot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "v0BmuW9dcCId"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\" Sigmoid function.\n",
    "    This function accepts any shape of np.ndarray object as input and perform sigmoid operation.\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def der_sigmoid(y):\n",
    "    \"\"\" First derivative of Sigmoid function.\n",
    "    The input to this function should be the value that output from sigmoid function.\n",
    "    \"\"\"\n",
    "    return y * (1 - y)\n",
    "\n",
    "\n",
    "class GenData:\n",
    "    @staticmethod\n",
    "    def _gen_linear(n=100):\n",
    "        \"\"\" Data generation (Linear)\n",
    "\n",
    "        Args:\n",
    "            n (int):    the number of data points generated in total.\n",
    "\n",
    "        Returns:\n",
    "            data (np.ndarray, np.float):    the generated data with shape (n, 2). Each row represents\n",
    "                a data point in 2d space.\n",
    "            labels (np.ndarray, np.int):    the labels that correspond to the data with shape (n, 1).\n",
    "                Each row represents a corresponding label (0 or 1).\n",
    "        \"\"\"\n",
    "        data = np.random.uniform(0, 1, (n, 2))\n",
    "\n",
    "        inputs = []\n",
    "        labels = []\n",
    "\n",
    "        for point in data:\n",
    "            inputs.append([point[0], point[1]])\n",
    "\n",
    "            if point[0] > point[1]:\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "\n",
    "        return np.array(inputs), np.array(labels).reshape((-1, 1))\n",
    "\n",
    "    @staticmethod\n",
    "    def _gen_xor(n=100):\n",
    "        \"\"\" Data generation (XOR)\n",
    "\n",
    "        Args:\n",
    "            n (int):    the number of data points generated in total.\n",
    "\n",
    "        Returns:\n",
    "            data (np.ndarray, np.float):    the generated data with shape (n, 2). Each row represents\n",
    "                a data point in 2d space.\n",
    "            labels (np.ndarray, np.int):    the labels that correspond to the data with shape (n, 1).\n",
    "                Each row represents a corresponding label (0 or 1).\n",
    "        \"\"\"\n",
    "        data_x = np.linspace(0, 1, n // 2)\n",
    "\n",
    "        inputs = []\n",
    "        labels = []\n",
    "\n",
    "        for x in data_x:\n",
    "            inputs.append([x, x])\n",
    "            labels.append(0)\n",
    "\n",
    "            if x == 1 - x:\n",
    "                continue\n",
    "\n",
    "            inputs.append([x, 1 - x])\n",
    "            labels.append(1)\n",
    "\n",
    "        return np.array(inputs), np.array(labels).reshape((-1, 1))\n",
    "\n",
    "    @staticmethod\n",
    "    def fetch_data(mode, n):\n",
    "        \"\"\" Data gather interface\n",
    "\n",
    "        Args:\n",
    "            mode (str): 'Linear' or 'XOR', indicate which generator is used.\n",
    "            n (int):    the number of data points generated in total.\n",
    "        \"\"\"\n",
    "        assert mode == 'Linear' or mode == 'XOR'\n",
    "\n",
    "        data_gen_func = {\n",
    "            'Linear': GenData._gen_linear,\n",
    "            'XOR': GenData._gen_xor\n",
    "        }[mode]\n",
    "\n",
    "        return data_gen_func(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "v0BmuW9dcCId"
   },
   "outputs": [],
   "source": [
    "class SimpleNet:\n",
    "    def __init__(self, num_step=2000, print_interval=100):\n",
    "        \"\"\" A hand-crafted implementation of simple network.\n",
    "\n",
    "        Args:\n",
    "            num_step (optional):    the total number of training steps.\n",
    "            print_interval (optional):  the number of steps between each reported number.\n",
    "        \"\"\"\n",
    "        self.num_step = num_step\n",
    "        self.print_interval = print_interval\n",
    "\n",
    "        # Model parameters initialization\n",
    "        # hidden layer 1: 100 nodes\n",
    "        # hidden layer 2: 10 nodes\n",
    "        # Please initiate your network parameters here.\n",
    "        self.w1 = np.random.uniform(0, 1, (2, 100))\n",
    "        self.w2 = np.random.uniform(0, 1, (100, 10))\n",
    "        self.w3 = np.random.uniform(0, 1, (10, 1))\n",
    "\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def plot_result(data, gt_y, pred_y):\n",
    "        \"\"\" Data visualization with ground truth and predicted data comparison. There are two plots\n",
    "        for them and each of them use different colors to differentiate the data with different labels.\n",
    "\n",
    "        Args:\n",
    "            data:   the input data\n",
    "            gt_y:   ground truth to the data\n",
    "            pred_y: predicted results to the data\n",
    "        \"\"\"\n",
    "        print(pred_y.shape[0])\n",
    "        assert data.shape[0] == gt_y.shape[0]\n",
    "        assert data.shape[0] == pred_y.shape[0]\n",
    "\n",
    "        plt.figure()\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title('Ground Truth', fontsize=18)\n",
    "\n",
    "        for idx in range(data.shape[0]):\n",
    "            if gt_y[idx] == 0:\n",
    "                plt.plot(data[idx][0], data[idx][1], 'ro')\n",
    "            else:\n",
    "                plt.plot(data[idx][0], data[idx][1], 'bo')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title('Prediction', fontsize=18)\n",
    "\n",
    "        for idx in range(data.shape[0]):\n",
    "            if pred_y[idx] == 0:\n",
    "                plt.plot(data[idx][0], data[idx][1], 'ro')\n",
    "            else:\n",
    "                plt.plot(data[idx][0], data[idx][1], 'bo')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Implementation of the forward pass.\n",
    "        It should accepts the inputs and passing them through the network and return results.\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\" FILL IN HERE \"\"\"\n",
    "        self.l1_out = np.zeros((inputs.shape[0], inputs.shape[1], self.w1.shape[-1]))\n",
    "        self.l2_out = np.zeros((inputs.shape[0], inputs.shape[1], self.w2.shape[-1]))\n",
    "        self.l3_out = np.zeros((inputs.shape[0], inputs.shape[1], self.w3.shape[-1]))\n",
    "        for i in range(inputs.shape[0]):\n",
    "            self.l1_out[i] = dot(inputs[i], self.w1)\n",
    "        output = sigmoid(self.l1_out)\n",
    "        for i in range(inputs.shape[0]):\n",
    "            self.l2_out[i] = dot(output[i], self.w2)\n",
    "        output = sigmoid(self.l2_out)\n",
    "        for i in range(inputs.shape[0]):\n",
    "            self.l3_out[i] = dot(output[i], self.w3)\n",
    "        output = sigmoid(self.l3_out)\n",
    "        return output\n",
    "\n",
    "    def backward(self, error):\n",
    "        \"\"\" Implementation of the backward pass.\n",
    "        It should utilize the saved loss to compute gradients and update the network all the way to the front.\n",
    "        \"\"\"\n",
    "        learning_rate = 1e-2\n",
    "\n",
    "        \"\"\" FILL IN HERE \"\"\"\n",
    "        w3_total = np.zeros(self.w3.shape)\n",
    "        w2_total = np.zeros(self.w2.shape)\n",
    "        w1_total = np.zeros(self.w1.shape)\n",
    "        for i in range(error.shape[0]):\n",
    "            w3_total += error[i] * der_sigmoid(self.l3_out[i])\n",
    "            w2_total += error[i] * der_sigmoid(self.l2_out[i])\n",
    "            w1_total += error[i] * der_sigmoid(self.l1_out[i])\n",
    "            \n",
    "        self.w3 -= (w3_total / error.shape[0])\n",
    "        self.w2 -= (w2_total / error.shape[0])\n",
    "        self.w1 -= (w1_total / error.shape[0])\n",
    "\n",
    "    def train(self, inputs, labels):\n",
    "        \"\"\" The training routine that runs and update the model.\n",
    "\n",
    "        Args:\n",
    "            inputs: the training (and testing) data used in the model.\n",
    "            labels: the ground truth of correspond to input data.\n",
    "        \"\"\"\n",
    "        # make sure that the amount of data and label is match\n",
    "        assert inputs.shape[0] == labels.shape[0]\n",
    "\n",
    "        n = inputs.shape[0]\n",
    "\n",
    "        for epochs in range(self.num_step):\n",
    "            for idx in range(n):\n",
    "                # operation in each training step:\n",
    "                #   1. forward passing\n",
    "                #   2. compute loss\n",
    "                #   3. propagate gradient backward to the front\n",
    "                self.output = self.forward(inputs[idx:idx+1, :])\n",
    "                self.error = self.output - labels[idx:idx+1, :]\n",
    "                \"\"\" apply your backward function: \"\"\"\n",
    "                \"\"\" FILL IN HERE \"\"\"\n",
    "                self.backward(self.error)\n",
    "\n",
    "            if epochs % self.print_interval == 0:\n",
    "                print('Epochs {}: '.format(epochs))\n",
    "                self.test(inputs, labels)\n",
    "\n",
    "        print('Training finished')\n",
    "        self.test(inputs, labels)\n",
    "\n",
    "    def test(self, inputs, labels):\n",
    "        \"\"\" The testing routine that run forward pass and report the accuracy.\n",
    "\n",
    "        Args:\n",
    "            inputs: the testing data. One or several data samples are both okay.\n",
    "                The shape is expected to be [BatchSize, 2].\n",
    "            labels: the ground truth correspond to the inputs.\n",
    "        \"\"\"\n",
    "        n = inputs.shape[0]\n",
    "\n",
    "        error = 0.0\n",
    "        for idx in range(n):\n",
    "            result = self.forward(inputs[idx:idx+1, :])\n",
    "            error += abs(result - labels[idx:idx+1, :])\n",
    "\n",
    "        error /= n\n",
    "\n",
    "        \"\"\" Print or plot your results in your preferred forms\"\"\"\n",
    "        print('accuracy: %.2f' % ((1 - error)*100) + '%')\n",
    "        \n",
    "        \"\"\" FILL IN HERE \"\"\"\n",
    "        # print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jK3VNavIFpa8"
   },
   "source": [
    "### Run \"Linear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "urzfLhyhET7b"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,1) (2,1) (10,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_288519/3905720901.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpred_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_288519/1163918549.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, inputs, labels)\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0;34m\"\"\" apply your backward function: \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0;34m\"\"\" FILL IN HERE \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_288519/1163918549.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, error)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mw1_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mw3_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mder_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml3_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0mw2_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mder_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mw1_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mder_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,1) (2,1) (10,1) "
     ]
    }
   ],
   "source": [
    "\"\"\" Customize your own code if needed \"\"\"\n",
    "\n",
    "data, label = GenData.fetch_data('Linear', 100)\n",
    "\n",
    "net = SimpleNet(100, 10)\n",
    "net.train(data, label)\n",
    "\n",
    "pred_result = np.round(net.forward(data))\n",
    "SimpleNet.plot_result(data, label, pred_result.T)\n",
    "\n",
    "\"\"\" FILL IN HERE \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJHxIo2yFeG8"
   },
   "source": [
    "### Run \"XOR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QzEKq9L5Ffu3"
   },
   "outputs": [],
   "source": [
    "\"\"\" Customize your own code if needed \"\"\"\n",
    "\n",
    "data, label = GenData.fetch_data('XOR', 100)\n",
    "\n",
    "net = SimpleNet(100, num_step=100)\n",
    "net.train(data, label)\n",
    "\n",
    "pred_result = np.round(net.forward(data))\n",
    "SimpleNet.plot_result(data, label, pred_result.T)\n",
    "\n",
    "\"\"\" FILL IN HERE \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = GenData.fetch_data('Linear', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "[[0.54573947 0.60082137 0.62389011 0.6742     0.60166128 0.67978776\n",
      "  0.61397753 0.58761779]]\n",
      "[[0.77660907 0.92323119 0.73214894 0.95209309 0.89836756 0.89623579\n",
      "  0.87905922 0.95863352]]\n",
      "[[0.98059695]]\n",
      "(1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(data[0:1, :].shape)\n",
    "d = data[0:1, :]\n",
    "w1 = np.random.uniform(0, 1, (d.shape[1], 8))\n",
    "w2 = np.random.uniform(0, 1, (w1.shape[1], 8))\n",
    "w3 = np.random.uniform(0, 1, (w2.shape[1], 1))\n",
    "\n",
    "print(sigmoid(dot(d, w1)))\n",
    "print(sigmoid(dot(sigmoid(dot(d, w1)), w2)))\n",
    "print(sigmoid(dot(sigmoid(dot(sigmoid(dot(d, w1)), w2)), w3)))\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.9045116114239506e-01\n"
     ]
    }
   ],
   "source": [
    "print(sigmoid(-0.0382))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SimpleNet(100, 10)\n",
    "a = net.forward([[0.5, 0.5],\n",
    "                 [0.1, 0.1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.37898586]\n",
      " [5.37898586]]\n"
     ]
    }
   ],
   "source": [
    "print(net.l3_out)\n",
    "# print(net.w1)\n",
    "# print(net.w1 - net.l1_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab_1_sample.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
